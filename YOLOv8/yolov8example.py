# -*- coding: utf-8 -*-
"""YOLOv8example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G_P3ctrCsW8or722rkwSPOH-IDO2evbE
"""

!pip install ultralytics

import os
import glob
import numpy as np
from PIL import Image
from ultralytics import YOLO
from google.colab import drive
drive.mount('/content/drive')

# Choose proper pretrained model from yolo v8: small size model for detection task
# Change model kind to nano for faster prediction and medium for more accurate prediction
# Change model type from detection to segmentaftion for more accurate background reduction
model = YOLO("yolov8m.pt")

os.chdir('/content/drive/MyDrive/CarCrashYOLO/images/test')

# Get the list of JPG files in the directory
jpg_files = os.listdir('.')
jpg_files = [file for file in jpg_files if file.lower().endswith('.jpg')][:2000]

# Run inference on 'bus.jpg'
results = model(jpg_files[7], iou=0.92)  # results list

# Show the results
for r in results:
    im_array = r.plot()  # plot a BGR numpy array of predictions
    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image
    im.show()  # show image
    display(im)
    print(r.boxes.data[:19])  # print the Boxes object containing the detection bounding boxes
    print(r.boxes.data[:19].shape)

# Run inference on 'bus.jpg'
results = model(jpg_files[1], iou=0.95) # results list

# Show the results
for r in results:
    im_array = r.plot()  # plot a BGR numpy array of predictions
    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image
    im.show()  # show image
    display(im)
print(r.boxes.data[:19])  # print the Boxes object containing the detection bounding boxes
print(r.boxes.data[:19].shape)

def draw_bounding_boxes(image, boxes):
    """
    Draw bounding boxes on an image.

    Parameters:
    image (numpy.ndarray): The image on which to draw.
    boxes (numpy.ndarray): A (19, 6) array where each row contains (x1, y1, x2, y2, probability, class).
    class_labels (list): A list of class labels.

    Returns:
    numpy.ndarray: The image with bounding boxes.
    """
    for box in boxes:
        x1, y1, x2, y2, prob, class_id = box
        class_id = int(class_id)

        # Draw the bounding box
        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)

        # Prepare the label text
        label = f"{class_id}: {prob:.2f}"

        # Calculate text width & height to draw the text background
        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
        text_x = int(x1)
        text_y = int(y1) - 10
        cv2.rectangle(image, (text_x, text_y), (text_x + text_size[0], text_y - text_size[1]), (255, 0, 0), cv2.FILLED)

        # Put the label text on the image
        cv2.putText(image, label, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    return image

root_pos = '/content/drive/MyDrive/CarCrash/vgg16_features/positive'
frame = jpg_files[0].split('.')[0]
video = frame.split('_')[0]
frame_num = frame.split('_')[1]
path = os.path.join(root_pos,  video+'.npz')
feature = np.load(path)
boxx = feature['det'][int(frame_num)]

boxx

import cv2
image = cv2.imread(jpg_files[0])
image_rgb = draw_bounding_boxes(image, boxx)
display(Image.fromarray(image_rgb))

def calculate_iou(box1, box2):
    """
    Calculate the Intersection over Union (IoU) of two bounding boxes.
    """
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])

    intersection_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)

    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])

    union_area = box1_area + box2_area - intersection_area

    iou = intersection_area / union_area
    return iou

def calculate_metrics(pred_boxes, true_boxes, iou_threshold=0.5):
    """
    Calculate metrics like IoU, Precision, Recall, and mAP for object detection.
    """
    true_positives = 0
    false_positives = 0
    false_negatives = len(true_boxes)

    for pred_box in pred_boxes:
        for true_box in true_boxes:
            iou = calculate_iou(pred_box[:4], true_box[:4])

            if iou > iou_threshold and pred_box[5] == true_box[5]: # Class label must also match
                true_positives += 1
                false_negatives -= 1
                break
        else:
            false_positives += 1

    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0

    # mAP calculation would require computing the precision-recall curve over varying thresholds
    # and is more complex to implement correctly. It's often done using additional libraries.

    return {
        'IoU': [calculate_iou(pred_box[:4], true_box[:4]) for pred_box, true_box in zip(pred_boxes, true_boxes)],
        'Precision': precision,
        'Recall': recall,
        # 'mAP': mAP  # mAP calculation is not included in this basic implementation
    }



